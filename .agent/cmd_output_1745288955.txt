## Handoff Document: llm-consortium - Robust Synthesis Logging

**Project:** `llm-consortium` Plugin (`irthomasthomas/llm-consortium`)
**Tracking Issue:** #8

### Current Status
*   **Conversation Continuation Feature:** Implemented and successfully tested using both `-c` and `--cid`. The plugin now correctly loads and utilizes conversation history.
*   **Bugs Fixed:**
    *   Corrected `ImportError` for `load_conversation` (now imported from `llm.cli`).
    *   Resolved `KeyError: 'confidence'` by adding default values during arbiter response parsing.
*   **Tests:** 'HONEYBADGER' memory tests passed for `4.1-n1` and `qwq-consortium`.
*   **Code Location:** `/home/thomas/Projects/llm/plugins/Utilities/llm-consortium/`
*   **State:** Awaiting execution of the next defined task.

### Completed Work Summary
*   Successfully debugged and implemented conversation history loading by correctly utilizing the `conversation` object passed by `llm` core to `ConsortiumModel.execute`.
*   Updated `ConsortiumOrchestrator.orchestrate` to accept pre-formatted history.
*   Updated GitHub issue #8 with research findings, implementation details, and successful test results.
*   Created and tested `monitor_issue.sh` script for awaiting user input via GitHub comments.

### Next Task: Robust Synthesis Extraction for Final Log Entry

**Goal:** Ensure the final, synthesized log entry created by `llm` (where `model` = consortium name, e.g., `4.1-n1`) has a clean and correct `response` field, and the correct original `prompt` field.

**Detailed Requirements:**
1.  **Clean Synthesis:** The `response` field of the final log entry should contain **only** the text extracted from the arbiter's final `<synthesis>...</synthesis>` block. Raw XML or the full arbiter output should *not* be present if parsing succeeds.
2.  **Fallback:** If extracting the synthesis text from the arbiter's response fails (due to parsing errors, missing tags, etc.), the `response` field of the final log entry should contain the **entire, raw text output** from the final arbiter model call.
3.  **Original Prompt Logging:** Verify and ensure that the `prompt` field of the final log entry contains **only** the original user prompt provided to the `llm` command, *not* the augmented prompt including history or system instructions.

### Key Files & Code Snippets for Next Task

1.  **`llm_consortium/__init__.py`:**
    *   **`_parse_arbiter_response(self, text: str, ...)`:**
        *   Likely needs modification to more robustly extract content within `<synthesis>...</synthesis>`.
        *   Must handle cases where tags are missing or malformed. Consider returning a specific signal (e.g., `None` or raising an exception) on failure, or perhaps return the raw `text` as the fallback synthesis directly.
        *   Current implementation adds defaults but might still return the full text if parsing fails early. Needs refinement for the fallback logic.
    *   **`ConsortiumModel.execute(...)`:**
        *   The final `return` value of this method is critical. It's what `llm` core uses to populate the `response` field of the final log entry.
        *   Currently returns `result["synthesis"]["synthesis"]`.
        *   Modify this to return the *clean* synthesis text if parsing succeeded, or the *raw arbiter response text* if parsing failed, based on the outcome of `_parse_arbiter_response`.
        *   Need to inspect the `result` structure returned by `orchestrate` to access both potential values.

2.  **`llm` Core Code (Reference - No Modification Needed Here):**
    *   `/home/thomas/Projects/llm/my-llm/llm/models.py`: See `Response.__iter__` (calls plugin's `execute`) and `Response.log_to_db` (handles logging). Understanding how the return value of `execute` maps to the logged `response` text is key.
    *   `/home/thomas/Projects/llm/my-llm/llm/cli.py`: Shows how `prompt` objects are created and passed initially.

### Debugging & Verification Strategy

1.  **Use Simple Consortia:** Test with `4.1-n1` or `qwq-consortium` (max/min iterations = 1).
    *   Example command: `llm -m 4.1-n1 "Simple test prompt"`
2.  **Inspect Logs:** Immediately after, run `llm logs -n 3 --json`. Examine the *third* log entry (where `model` is `4.1-n1`).
    *   Check the `"response"` field: Does it contain clean text or raw arbiter output (potentially with XML)?
    *   Check the `"prompt"` field: Does it contain only "Simple test prompt" or more?
3.  **Simulate Parsing Failure:** Temporarily modify `_parse_arbiter_response` to *always* fail extraction (e.g., return a placeholder or raise an error handled by `execute`) and verify that the raw arbiter text is logged correctly as the fallback.
4.  **Verify Prompt Field:** If the logged `prompt` is incorrect (includes history/system), trace how the `Prompt` object associated with the final `Response` logged by `log_to_db` is populated. It *should* typically be the original user prompt.

### Using `monitor_issue.sh`

*   **Purpose:** To wait for new instructions or feedback from user `irthomasthomas` on GitHub issue #8.
*   **How to Run:** After completing a task or when requiring input, execute:
    ```bash
    /home/thomas/Projects/llm/plugins/Utilities/llm-consortium/monitor_issue.sh
    ```
*   **Behavior:** The script will block (pause execution). Debug messages showing polling activity will appear on stderr. When a new comment from `irthomasthomas` is found, the script will print the **comment body** to standard output and then exit.
*   **Action on Output:** Treat the output (the comment body) as the next instruction. If the comment asks for a reply *on GitHub*, use the `gh issue comment ...` command (preferably with `--body-file` for complex replies). Otherwise, proceed with the task described in the comment.

**Next Action:** Implement the robust synthesis extraction and logging logic as defined above.
Stdout/Stderr: ## Handoff Document: llm-consortium - Robust Synthesis Logging

**Project:** `llm-consortium` Plugin (`irthomasthomas/llm-consortium`)
**Tracking Issue:** #8

### Current Status
*   **Conversation Continuation Feature:** Implemented and successfully tested using both `-c` and `--cid`. The plugin now correctly loads and utilizes conversation history.
*   **Bugs Fixed:**
    *   Corrected `ImportError` for `load_conversation` (now imported from `llm.cli`).
    *   Resolved `KeyError: 'confidence'` by adding default values during arbiter response parsing.
*   **Tests:** 'HONEYBADGER' memory tests passed for `4.1-n1` and `qwq-consortium`.
*   **Code Location:** `/home/thomas/Projects/llm/plugins/Utilities/llm-consortium/`
*   **State:** Awaiting execution of the next defined task.

### Completed Work Summary
*   Successfully debugged and implemented conversation history loading by correctly utilizing the `conversation` object passed by `llm` core to `ConsortiumModel.execute`.
*   Updated `ConsortiumOrchestrator.orchestrate` to accept pre-formatted history.
*   Updated GitHub issue #8 with research findings, implementation details, and successful test results.
*   Created and tested `monitor_issue.sh` script for awaiting user input via GitHub comments.

### Next Task: Robust Synthesis Extraction for Final Log Entry

**Goal:** Ensure the final, synthesized log entry created by `llm` (where `model` = consortium name, e.g., `4.1-n1`) has a clean and correct `response` field, and the correct original `prompt` field.

**Detailed Requirements:**
1.  **Clean Synthesis:** The `response` field of the final log entry should contain **only** the text extracted from the arbiter's final `<synthesis>...</synthesis>` block. Raw XML or the full arbiter output should *not* be present if parsing succeeds.
2.  **Fallback:** If extracting the synthesis text from the arbiter's response fails (due to parsing errors, missing tags, etc.), the `response` field of the final log entry should contain the **entire, raw text output** from the final arbiter model call.
3.  **Original Prompt Logging:** Verify and ensure that the `prompt` field of the final log entry contains **only** the original user prompt provided to the `llm` command, *not* the augmented prompt including history or system instructions.

### Key Files & Code Snippets for Next Task

1.  **`llm_consortium/__init__.py`:**
    *   **`_parse_arbiter_response(self, text: str, ...)`:**
        *   Likely needs modification to more robustly extract content within `<synthesis>...</synthesis>`.
        *   Must handle cases where tags are missing or malformed. Consider returning a specific signal (e.g., `None` or raising an exception) on failure, or perhaps return the raw `text` as the fallback synthesis directly.
        *   Current implementation adds defaults but might still return the full text if parsing fails early. Needs refinement for the fallback logic.
    *   **`ConsortiumModel.execute(...)`:**
        *   The final `return` value of this method is critical. It's what `llm` core uses to populate the `response` field of the final log entry.
        *   Currently returns `result["synthesis"]["synthesis"]`.
        *   Modify this to return the *clean* synthesis text if parsing succeeded, or the *raw arbiter response text* if parsing failed, based on the outcome of `_parse_arbiter_response`.
        *   Need to inspect the `result` structure returned by `orchestrate` to access both potential values.

2.  **`llm` Core Code (Reference - No Modification Needed Here):**
    *   `/home/thomas/Projects/llm/my-llm/llm/models.py`: See `Response.__iter__` (calls plugin's `execute`) and `Response.log_to_db` (handles logging). Understanding how the return value of `execute` maps to the logged `response` text is key.
    *   `/home/thomas/Projects/llm/my-llm/llm/cli.py`: Shows how `prompt` objects are created and passed initially.

### Debugging & Verification Strategy

1.  **Use Simple Consortia:** Test with `4.1-n1` or `qwq-consortium` (max/min iterations = 1).
    *   Example command: `llm -m 4.1-n1 "Simple test prompt"`
2.  **Inspect Logs:** Immediately after, run `llm logs -n 3 --json`. Examine the *third* log entry (where `model` is `4.1-n1`).
    *   Check the `"response"` field: Does it contain clean text or raw arbiter output (potentially with XML)?
    *   Check the `"prompt"` field: Does it contain only "Simple test prompt" or more?
3.  **Simulate Parsing Failure:** Temporarily modify `_parse_arbiter_response` to *always* fail extraction (e.g., return a placeholder or raise an error handled by `execute`) and verify that the raw arbiter text is logged correctly as the fallback.
4.  **Verify Prompt Field:** If the logged `prompt` is incorrect (includes history/system), trace how the `Prompt` object associated with the final `Response` logged by `log_to_db` is populated. It *should* typically be the original user prompt.

### Using `monitor_issue.sh`

*   **Purpose:** To wait for new instructions or feedback from user `irthomasthomas` on GitHub issue #8.
*   **How to Run:** After completing a task or when requiring input, execute:
    ```bash
    /home/thomas/Projects/llm/plugins/Utilities/llm-consortium/monitor_issue.sh
    ```
*   **Behavior:** The script will block (pause execution). Debug messages showing polling activity will appear on stderr. When a new comment from `irthomasthomas` is found, the script will print the **comment body** to standard output and then exit.
*   **Action on Output:** Treat the output (the comment body) as the next instruction. If the comment asks for a reply *on GitHub*, use the `gh issue comment ...` command (preferably with `--body-file` for complex replies). Otherwise, proceed with the task described in the comment.

**Next Action:** Implement the robust synthesis extraction and logging logic as defined above.
Exit Code: 
