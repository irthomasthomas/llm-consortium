Stdout/Stderr: https://github.com/irthomasthomas/llm-consortium/issues/8#issuecomment-2817371598
diff --git a/llm_consortium/__init__.py b/llm_consortium/__init__.py
index 0da4dc3..0d9aae2 100644
--- a/llm_consortium/__init__.py
+++ b/llm_consortium/__init__.py
@@ -166,7 +166,7 @@ class ConsortiumOrchestrator:
         self.arbiter = config.arbiter or "gemini-2.0-flash"
         self.iteration_history: List[IterationContext] = []
         # New: Dictionary to track conversation IDs for each model instance
-        self.conversation_ids: Dict[str, str] = {}
+        # self.conversation_ids: Dict[str, str] = {}
 
     def orchestrate(self, prompt: str) -> Dict[str, Any]:
         iteration_count = 0
@@ -247,22 +247,7 @@ class ConsortiumOrchestrator:
     <instruction>{prompt}</instruction>
 </prompt>"""
                 
-                # Check if we have an existing conversation for this model instance
-                conversation_id = self.conversation_ids.get(instance_key)
-                click.echo(f"Conversation ID for {instance_key}: {conversation_id}")
-                # If we have a conversation_id, continue that conversation
-                if conversation_id:
-                    response = llm.get_model(model).prompt(
-                        xml_prompt,
-                        conversation_id=conversation_id
-                    )
-                else:
-                    # Start a new conversation
-                    response = llm.get_model(model).prompt(xml_prompt)
-                    # Store the conversation_id for future iterations
-                    if hasattr(response, 'conversation_id') and response.conversation_id:
-                        self.conversation_ids[instance_key] = response.conversation_id
-                        click.echo(f"New conversation ID for {instance_key}: {response.conversation_id}")
+                response = llm.get_model(model).prompt(xml_prompt)
                 
                 text = response.text()
                 log_response(response, f"{model}-{instance + 1}")
@@ -271,7 +256,6 @@ class ConsortiumOrchestrator:
                     "instance": instance + 1,
                     "response": text,
                     "confidence": self._extract_confidence(text),
-                    "conversation_id": getattr(response, 'conversation_id', None)
                 }
             except Exception as e:
                 # Check if the error is a rate-limit error
@@ -524,7 +508,6 @@ class ConsortiumModel(llm.Model):
 
     def execute(self, prompt, stream, response, conversation):
         """Execute the consortium synchronously"""
-        click.echo(f"conversation_id: {conversation}")
         try:
             # Check if a system prompt was provided via --system option
             if hasattr(prompt, 'system') and prompt.system:
Exit Code: 0
